name:
  swe: SweWinograd 2.0
  eng: SweWinograd 2.0
short_description:
  swe: En svensk datamängd för pronomentolkning
  eng: A Swedish dataset for pronoun resolution
type: corpus
trainingdata: true
unlisted: false
successors: []
language_codes:
  - swe
size:
  tokens: 0
in_collections:
  - superlim
downloads:
  - url: https://svn.spraakdata.gu.se/sb-arkiv/pub/swewinograd/2.0/swewinograd.zip
    type: an archive with the dataset in JSONL format and the documentation sheet
    format: zip
    info: null
    licence: CC BY 4.0
    restriction: attribution
interface: []
contact_info:
  name: Gerlof Bouma
  email: sb-info@svenska.gu.se
  affiliation:
    organisation: Språkbanken
    email: sb-info@svenska.gu.se
description:
  swe: ''
  eng: |-
    <table style="width:100%">
    <tr>
    <td>I. IDENTIFYING INFORMATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Title*</td>
    <td>SweWinograd v2.0
    </td>
    </tr>
    <tr>
    <td>Subtitle</td>
    <td>A Swedish coreference test set in the style of the Winograd Schema Challenge
    </td>
    </tr>
    <tr>
    <td>Created by*</td>
    <td>Yvonne Adesam (yvonne.adesam@gu.se), Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>Publisher(s)*</td>
    <td>Språkbanken Text
    </td>
    </tr>
    <tr>
    <td>Link(s) / permanent identifier(s)*</td>
    <td>https://spraakbanken.gu.se/en/resources/swewinograd
    </td>
    </tr>
    <tr>
    <td>License(s)*</td>
    <td>CC BY 4.0
    </td>
    </tr>
    <tr>
    <td>Abstract*</td>
    <td>SweWinograd is a pronoun resolution test set, containing constructed items in the style of Winograd schema’s. The interpretation of the target pronouns is intended to be determined by (common sense) reasoning and knowledge, and not by syntactic constraints, lexical distributional information or discourse structuring patterns. The dataset contains 90 multiple choice with multiple correct answers test items.
    </td>
    </tr>
    <tr>
    <td>Funded by*</td>
    <td>Vinnova (dnr 2020-02523; dnr 2021-04165)
    </td>
    </tr>
    <tr>
    <td>Cite as</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related datasets</td>
    <td>Part of the SuperLim 2.0 collection (https://spraakbanken.gu.se/en/resources/superlim)
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>II. USAGE</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Key applications</td>
    <td>Evaluation of coreference resolution systems
    </td>
    </tr>
    <tr>
    <td>Intended task(s)/usage(s)</td>
    <td>Decide for each test item whether the indicated pronoun and candidate antecedent corefer in the supplied context (mention-pair style).
    </td>
    </tr>
    <tr>
    <td>Recommended evaluation measures</td>
    <td>Krippendorff's alpha.
    </td>
    </tr>
    <tr>
    <td>Dataset function(s)</td>
    <td>Training and testing.
    </td>
    </tr>
    <tr>
    <td>Recommended split(s)</td>
    <td>Train, dev and testsplits as indicated in filenames.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>III. DATA</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Primary data*</td>
    <td>Text
    </td>
    </tr>
    <tr>
    <td>Language*</td>
    <td>Swedish
    </td>
    </tr>
    <tr>
    <td>Dataset in numbers*</td>
    <td>Training data: 721 items, of which 339 positive (=coreferring) and 382 negative.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Development data: 135 items, 55 positive, 80 negative.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Test data: 140 items, 43 positive, 97 negative. 
    </td>
    </tr>
    <tr>
    <td>Nature of the content*</td>
    <td>Each test item consists of a short discourse with a target pronoun to be resolved, a non-pronominal candidate antecedent for the pronoun, and a judgement of whether the two corefer. The candidates are all syntactically and semantically compatible – common sense reasoning is needed to resolve the pronouns correctly. The same sentence-pronoun pair may appear in multiple items, with different candidate antecedents, multiple of these may be cases of corefererence. In some cases, the same discourse is used in items with different target pronouns. Furthermore, some items are like the original Winograd sentence(s), by coming in pairs, where the first half of the discourse is the same, but the second half differs in a way that effects the interpretation of the target pronoun.
    </td>
    </tr>
    <tr>
    <td>Format*</td>
    <td>JSON Lines, with 1 test item per line. Sentences are given as strings ('text' attribute), pronouns and candidate antecedents as objects that combine of strings ('text') and string indices ('start', 'stop'). Indices are 0-based and half-open. and refer to the NFKC-normalized unicode string. The information of whether a pair corefers or not is given in the 'label' attribute. Metadata ('meta' attribute) included for each item is intended for analysis, not for use by the pronoun resolution system.
    </td>
    </tr>
    <tr>
    <td>Data source(s)*</td>
    <td>The items are loose translations of and/or inspired by the items in the Winograd task of SuperGlue (see https://super.gluebenchmark.com/tasks and [1]).
    </td>
    </tr>
    <tr>
    <td>Data collection method(s)*</td>
    <td>Fully manual translation/item construction.
    </td>
    </tr>
    <tr>
    <td>Data selection and filtering*</td>
    <td>(does not apply)
    </td>
    </tr>
    <tr>
    <td>Data preprocessing*</td>
    <td>(does not apply)
    </td>
    </tr>
    <tr>
    <td>Data labeling*</td>
    <td>Gold-standard coreference information.
    </td>
    </tr>
    <tr>
    <td>Annotator characteristics</td>
    <td>Compiled/translated by 1 native speaker of Swedish with PhD in computational linguistics, 1 near-native speaker of Swedish with PhD in (corpus) linguistics. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>IV. ETHICS AND CAVEATS</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Ethical considerations</td>
    <td>None to report
    </td>
    </tr>
    <tr>
    <td>Things to watch out for</td>
    <td>Version 1.0 of the SweWinograd data has a different problem formulation and a test set that is comprised of the combined dev and test sets of version 2.0 (this version). The test data of version 1.0 should therefore not be used to evaluated models trained on this versions train and dev data.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>V. ABOUT DOCUMENTATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Data last updated*</td>
    <td>20230126 v2.0
    </td>
    </tr>
    <tr>
    <td>Which changes have been made, compared to the previous version*</td>
    <td>Created training data. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Reorganized existing data into dev and test.
    </td>
    </tr>
    <tr>
    <td>Access to previous versions</td>
    <td>Previous versions available from website.
    </td>
    </tr>
    <tr>
    <td>This document created*</td>
    <td>20210614, Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>This document last updated*</td>
    <td>20230208, Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>Where to look for further details</td>
    <td>-
    </td>
    </tr>
    <tr>
    <td>Documentation template version*</td>
    <td>v1.1
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>VI. OTHER</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related projects</td>
    <td>SweWinograd is based upon the Winograd task as distributed with SuperGlue. See https://super.gluebenchmark.com/ and the discussion in [1].
    </td>
    </tr>
    <tr>
    <td></td>
    <td>The SuperGlue task itself is derived from Winograd Schema Challenge, see [2] for the paper introducing this dataset and the companion website https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html for more information and links to further papers on this data.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>References</td>
    <td>[1] Wang, Pruksachatkun, Nangia, Singh, Michael, Hill, Levy and Bowman (2019): SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. In Advances in Neural Information Processing Systems 32. https://papers.nips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[2] Levesque, Davis and Morgenstern (2012): The Winograd schema challenge. In: Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning. http://dl.acm.org/citation.cfm?id=3031843.3031909.
    </td>
    </tr>
    </table>
    