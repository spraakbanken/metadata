name:
  swe: SuperSim (paketterat för Superlim) 2.0
  eng: SuperSim (repackaged for Superlim) 2.0
short_description:
  swe: En datamängd för betydelsemässig likhet och koppling mellan svenska ord.
  eng: A dataset for word similarity and relatedness in Swedish
type: corpus
trainingdata: true
unlisted: false
successors: []
language_codes:
  - swe
in_collections:
  - superlim
downloads:
  - url: https://svn.spraakdata.gu.se/sb-arkiv/pub/supersim-superlim/1.1/supersim-superlim.zip
    type: an archive with the dataset in JSONL and TSV formats and the documentation sheet
    format: zip
    licence: CC BY 4.0
    restriction: attribution
interface: []
creators:
  - Hengchen, Simon
  - Tahmasebi, Nina
contact_info:
  name: Yvonne Adesam
  email: sb-info@svenska.gu.se
  affiliation:
    organisation: Språkbanken
    email: sb-info@svenska.gu.se
description:
  swe: ''
  eng: |-
    <table style="width:100%">
    <tr>
    <td>I. IDENTIFYING INFORMATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Title*</td>
    <td>SuperSim (repackaged for Superlim) v1.1
    </td>
    </tr>
    <tr>
    <td>Subtitle</td>
    <td>A test set for word similarity and relatedness in Swedish 
    </td>
    </tr>
    <tr>
    <td>Created by*</td>
    <td>Simon Hengchen (simon.hengchen@gu.se), Nina Tahmasebi (nina.tahmasebi@gu.se)
    </td>
    </tr>
    <tr>
    <td>Publisher(s)*</td>
    <td>Språkbanken Text
    </td>
    </tr>
    <tr>
    <td>Link(s) / permanent identifier(s)*</td>
    <td>https://spraakbanken.gu.se/en/resources/superlim
    </td>
    </tr>
    <tr>
    <td>License(s)*</td>
    <td>CC BY 4.0
    </td>
    </tr>
    <tr>
    <td>Abstract*</td>
    <td>SuperSim is a large-scale similarity and relatedness test set  for  Swedish  built  with  expert  human judgments. The test set is composed  of 1360 word-pairs independently judged for both relatedness and similarity by five annotators.
    </td>
    </tr>
    <tr>
    <td>Funded by*</td>
    <td>Swedish Research Council (grant no. 2018-01184 to Nina Tahmasebi); Språkbanken Text
    </td>
    </tr>
    <tr>
    <td>Cite as</td>
    <td>[1]
    </td>
    </tr>
    <tr>
    <td>Related datasets</td>
    <td>See https://doi.org/10.5281/zenodo.4660084 for the complete data set accompanying [1], including baseline models and corpus material. The data described in this documentation sheet is the gold data from this larger archive. This repackaging of the gold data was done in the context of the SuperLim collection. See https://spraakbanken.gu.se/en/resources/superlim
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>II. USAGE</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Key applications</td>
    <td>Evaluation of language models
    </td>
    </tr>
    <tr>
    <td>Intended task(s)/usage(s)</td>
    <td>(1) Predict semantic similarity of word pairs from a language model
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(2) Predict semantic relatedness of word paris from a language model
    </td>
    </tr>
    <tr>
    <td>Recommended evaluation measures</td>
    <td>Krippendorff's alpha (the official SuperLim measure), Spearman's rho
    </td>
    </tr>
    <tr>
    <td>Dataset function(s)</td>
    <td>Few-shot training ("prompting"), testing
    </td>
    </tr>
    <tr>
    <td>Recommended split(s)</td>
    <td>A few-shot training set (aka "prompt", 10%), test set (90%). The prompt was added with the GPT-like models in mind. For those models that do not need a prompt, it can be ignored. The word pairs in the train test are the same for the two tasks.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>III. DATA</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Primary data*</td>
    <td>Text
    </td>
    </tr>
    <tr>
    <td>Language*</td>
    <td>Swedish
    </td>
    </tr>
    <tr>
    <td>Dataset in numbers*</td>
    <td>1360 word pairs with semantic similarity and semantic relatedness scores, of those 131 train items and 1229 test items.
    </td>
    </tr>
    <tr>
    <td>Nature of the content*</td>
    <td>Semantic similarity refers to the extent to which two concepts share semantic properties. Synonymy is the culmination of this concept. Relatedness is a looser lexical conceptual relation that refers to the general (psychological) assocation that may arise for instance because there are causal or instrumental relations between two concepts, or because concepts co-occur frequently, etc, etc. Similarity and relatedness are given as scores between 0 and 10, these scores are in turn averages of judgements on an 11-point scale (0–10).
    </td>
    </tr>
    <tr>
    <td>Format*</td>
    <td>The data is split over two files, one for each score. The files are provided both as JSONL and tab separated. TSVs contain the following 8 columns:
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(1) word 1
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(2) word 2
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(3)–(7) individual annotator scores (integer valued)
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(8) average score (real valued)
    </td>
    </tr>
    <tr>
    <td>Data source(s)*</td>
    <td>The word pairs were translated from SimLex-999 [2] and WordSim353 [3]. The complete set was manually checked and if needed pairs were adjusted (split into multiple or removed) depending on the lexical distinctions made in Swedish. The similarity and relatedness judgements were collected from five annotators, who were paid for the assignment. One of the annotators was also involved in translating the dataset. See discussion in [1].
    </td>
    </tr>
    <tr>
    <td>Data collection method(s)*</td>
    <td>Online collection of judgements from (paid) annotators. Annotators used written instructions from SimLex-999 [2]. See discussion in [1].
    </td>
    </tr>
    <tr>
    <td>Data selection and filtering*</td>
    <td>See discussion in [1]
    </td>
    </tr>
    <tr>
    <td>Data preprocessing*</td>
    <td>See discussion in [1]
    </td>
    </tr>
    <tr>
    <td>Data labeling*</td>
    <td>Both the similarity and relatedness scores are manual (gold standard).
    </td>
    </tr>
    <tr>
    <td>Annotator characteristics</td>
    <td>All annotators are native speakers of Swedish who hold linguistic degrees. Two have prior lexicographic experience. See [1] for more details.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>IV. ETHICS AND CAVEATS</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Ethical considerations</td>
    <td>None to report.
    </td>
    </tr>
    <tr>
    <td>Things to watch out for</td>
    <td>The word pairs are presented out of context. Superlim presently does not prescribe a methodology for the application of contextual (dynamic) language models to this data, which means we can expect considerable variation between test data uses. For reasons of comparability and reproducability, users must make sure to report their chosen method clearly. See also the remarks in the FAQ on https://spraakbanken.gu.se/resurser/superlim
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>V. ABOUT DOCUMENTATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Data last updated*</td>
    <td>20220920 (v1.1), Aleksandrs Berdicevskis
    </td>
    </tr>
    <tr>
    <td>Which changes have been made, compared to the previous version*</td>
    <td>Minor format changes
    </td>
    </tr>
    <tr>
    <td>Access to previous versions</td>
    <td>Work in progress
    </td>
    </tr>
    <tr>
    <td>This document created*</td>
    <td>20210611, Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>This document last updated*</td>
    <td>20230203, Aleksandrs Berdicevskis
    </td>
    </tr>
    <tr>
    <td>Where to look for further details</td>
    <td>The attached readme file
    </td>
    </tr>
    <tr>
    <td>Documentation template version*</td>
    <td>v1.1
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>VI. OTHER</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related projects</td>
    <td>SimLex-999 [2]; WordSim353 [3]
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>References</td>
    <td>[1] Hengchen and Tahmasebi (2021): SuperSim: a test set for word similarity and relatedness in Swedish. In Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). https://ep.liu.se/ecp/178/027/ecp2021178027.pdf
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[2] Hill, Reichart and Korhonen (2015): SimLex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics, 41(4): 665–695. https://doi.org/10.1162/COLI_a_00237
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[3] Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman and Ruppin (2002): Placing Search in Context: The Concept Revisited. ACM Transactions on Information Systems, 20(1):116-131. https://doi.org/10.1145/503104.503110
    </td>
    </tr>
    </table>
updated: 2023-03-30
doi: 10.23695/vbqg-jr16
