name:
  swe: SveParafras 2.0
  eng: SweParaphrase 2.0
short_description:
  swe: Referensdatan för semantisk textjämförelse (STS Benchmark)
  eng: Semantic Textual Similarity reference data (STS Benchmark).
type: corpus
trainingdata: true
unlisted: false
successors: []
language_codes:
  - swe
in_collections:
  - superlim
downloads:
  - url: https://svn.spraakbanken.gu.se/sb-arkiv/pub/sweparaphrase/2.0/sweparaphrase.zip
    description: an archive with the dataset in JSONL and TSV formats and the documentation sheet
    format: zip
    license: CC BY 4.0
interfaces: []
creators:
  - Dannélls, Dana
contact_info:
  name: Dana Dannélls
  email: dana.dannells@svenska.gu.se
  affiliation:
    organization: Språkbanken Text
    email: sb-info@svenska.gu.se
description:
  swe: ''
  eng: |-
    <table style="width:100%">
    <tr>
    <td>I. IDENTIFYING INFORMATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Title*</td>
    <td>SweParaphrase v2.0
    </td>
    </tr>
    <tr>
    <td>Subtitle</td>
    <td>Sentence-level semantic similarity dataset (a subset of the Swedish STS Benchmark).
    </td>
    </tr>
    <tr>
    <td>Created by*</td>
    <td>Dana Dannélls (dana.dannells@svenska.gu.se)
    </td>
    </tr>
    <tr>
    <td>Publisher(s)*</td>
    <td>Språkbanken Text (sb-info@svenska.gu.se)
    </td>
    </tr>
    <tr>
    <td>Link(s) / permanent identifier(s)*</td>
    <td>https://spraakbanken.gu.se/en/resources/sweparaphrase
    </td>
    </tr>
    <tr>
    <td>License(s)*</td>
    <td>The text of each dataset has a license of its own, as specified here <http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz>
    </td>
    </tr>
    <tr>
    <td>Abstract*</td>
    <td>SweParaphrase is a sentence similarity test and training set, containing sentence pairs and their similarity scores ranging between 0 (no semantic overlap) and 5 (semantic equivalence). These sentences were automatically translated from the English STS-B data and manually corrected by a native speaker of Swedish with background in linguistics.  
    </td>
    </tr>
    <tr>
    <td>Funded by*</td>
    <td>Vinnova (grants no. 2020-02523, 2021-04165) 
    </td>
    </tr>
    <tr>
    <td>Cite as</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related datasets</td>
    <td>Part of the SuperLim collection <https://spraakbanken.gu.se/en/resources/superlim>. Created from the development version of the automatically translated Swedish STS Benchmark <https://github.com/timpal0l/sts-benchmark-swedish>, that were translated from the English source <http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark>. Similarity scores were kept unchanged. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>II. USAGE</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Key applications</td>
    <td>Machine Translation, Question Answering, Information Retrieval, Text classification, Semantic parsing, Evaluation of language models.
    </td>
    </tr>
    <tr>
    <td>Intended task(s)/usage(s)</td>
    <td>Given two sentences determine how similar they are.
    </td>
    </tr>
    <tr>
    <td>Recommended evaluation measures</td>
    <td>'Krippendorff''s alpha (the official SuperLim measure), Pearson or Spearman correlation coefficients'
    </td>
    </tr>
    <tr>
    <td>Dataset function(s)</td>
    <td>Training, testing and development 
    </td>
    </tr>
    <tr>
    <td>Recommended split(s)</td>
    <td>Train, dev and test (provided)
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>III. DATA</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Primary data*</td>
    <td>Text
    </td>
    </tr>
    <tr>
    <td>Language*</td>
    <td>Swedish
    </td>
    </tr>
    <tr>
    <td>Dataset in numbers*</td>
    <td>8592 sentence pairs; 3 genres; 9 sources. 
    </td>
    </tr>
    <tr>
    <td>Nature of the content*</td>
    <td>Each pair belongs to one genre (e.g. news, forums or captions) and is linked to a file from source (e.g. headlines, answers-forums, images). The English pairs from which the Swedish sentences were translated are also included.
    </td>
    </tr>
    <tr>
    <td>Format*</td>
    <td>JSONL and TSV with the following columns/objects:
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(1) Sentence ID from the automatically translated Swedish dataset; 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(2) Genre from source (captions, news, forum);
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(3) File from source (images, headlines, answers);
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(4) and (5) manually corrected Swedish sentence pairs;
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(6) Similarity score from source (based on the English sentence pairs done by Crowdsourcing through Mechanical Turk).
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Data source(s)*</td>
    <td>The original STS benchmark comprises 8628 sentence pairs, collected from SemEval 2012 (task 6), 2014 (task 10), 2015 (task 2), 2016 (task 1), 2017 (task 1) and *SEM 2013.  
    </td>
    </tr>
    <tr>
    <td>Data collection method(s)*</td>
    <td>The original English STS-B dataset taken from the SemEval shared tasks [2] was automatically translated by a master student at the MLT program at GU using Google translate API in 2022 [3]. This automatically translated version can be downloaded from Språkbanken Text [4].
    </td>
    </tr>
    <tr>
    <td>Data selection and filtering*</td>
    <td>The automatically translated STS-B from 2022 [4] was manually corrected by a graduate student with background in linguistics.  
    </td>
    </tr>
    <tr>
    <td>Data preprocessing*</td>
    <td>English sentence pairs were tab-separated. Scores with decimals longer than 4 were shortened.
    </td>
    </tr>
    <tr>
    <td>Data labeling*</td>
    <td>No additional labeling was added. In the English version each sentence pair is annotated with a score (0-5), annotation was done by Crowdsourcing through Mechanical Turk. In the Swedish version we kept the scores that were assigned to the source English pairs.
    </td>
    </tr>
    <tr>
    <td>Annotator characteristics</td>
    <td>Native speaker of Swedish; fluent non-native speaker of Swedish
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>IV. ETHICS AND CAVEATS</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Ethical considerations</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Things to watch out for</td>
    <td>The similarity scores are based on the English data and are not necessarily representative for the Swedish counter parts. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>V. ABOUT DOCUMENTATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Data last updated*</td>
    <td>2022-08-25, v2.0, Dana Dannélls
    </td>
    </tr>
    <tr>
    <td>Which changes have been made, compared to the previous version*</td>
    <td>Train and dev sets have been added
    </td>
    </tr>
    <tr>
    <td>Access to previous versions</td>
    <td>Work in progress
    </td>
    </tr>
    <tr>
    <td>This document created*</td>
    <td>2023-02-08, Dana Dannélls
    </td>
    </tr>
    <tr>
    <td>This document last updated*</td>
    <td>2023-02-03, Aleksandrs Berdicevskis
    </td>
    </tr>
    <tr>
    <td>Where to look for further details</td>
    <td>[1],[2],[3], [4]
    </td>
    </tr>
    <tr>
    <td>Documentation template version*</td>
    <td>v1.1
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>VI. OTHER</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related projects</td>
    <td>Language models for Swedish authorities, Vinnova (grant no. 2019-02996) <https://www.vinnova.se/en/p/language-models-for-swedish-authorities/>.
    </td>
    </tr>
    <tr>
    <td>References</td>
    <td>[1] Isbister, T. and Sahlgren, M. (2020): Why not simply translate? A first Swedish evaluation benchmark for semantic similarity. Proceedings of the Eighth Swedish Language Technology Conference (SLTC), University of Gothenburg. <https://gubox.box.com/v/SLTC-2020-paper-15>. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td></td>
    </tr>
    <tr>
    <td></td>
    <td></td>
    </tr>
    <tr>
    <td></td>
    <td></td>
    </tr>
    </table>
updated: 2023-03-30
doi: 10.23695/hxhx-1167
