name:
  swe: SweWinogender 2.0
  eng: SweWinogender 2.0
short_description:
  swe: En svensk datamängd för koreferens och könsbias
  eng: A Swedish dataset for coreference and gender bias
type: corpus
trainingdata: true
unlisted: false
successors: []
language_codes:
  - swe
in_collections:
  - superlim
downloads:
  - url: https://svn.spraakdata.gu.se/sb-arkiv/pub/swewinogender/2.0/swewinogender.zip
    type: an archive with the dataset in JSONL format and the documentation sheet
    format: zip
    info: ''
    licence: CC BY 4.0
    restriction: attribution
interface: []
creators:
  - Adesam, Yvonne
  - Bouma, Gerlof
contact_info:
  name: Gerlof Bouma
  email: sb-info@svenska.gu.se
  affiliation:
    organisation: Språkbanken
    email: sb-info@svenska.gu.se
description:
  swe: ''
  eng: |-
    <table style="width:100%">
    <tr>
    <td>I. IDENTIFYING INFORMATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Title*</td>
    <td>SweWinogender v2.0
    </td>
    </tr>
    <tr>
    <td>Subtitle</td>
    <td>A Swedish diagnostic set for gender bias in natural language inference models
    </td>
    </tr>
    <tr>
    <td>Created by*</td>
    <td>Yvonne Adesam (yvonne.adesam@gu.se), Gerlof Bouma (gerlof.bouma)
    </td>
    </tr>
    <tr>
    <td>Publisher(s)*</td>
    <td>Språkbanken Text
    </td>
    </tr>
    <tr>
    <td>Link(s) / permanent identifier(s)*</td>
    <td>https://spraakbanken.gu.se/en/resources/swewinogender
    </td>
    </tr>
    <tr>
    <td>License(s)*</td>
    <td>CC BY 4.0
    </td>
    </tr>
    <tr>
    <td>Abstract*</td>
    <td>The SweWinogender test set is diagnostic dataset to measure gender bias in coreference resolution/textual entailment. It is modelled after the English Winogender benchmark, and is released with reference statistics on the distribution of men and women between occupations and the association between gender and occupation in modern corpus material. 
    </td>
    </tr>
    <tr>
    <td>Funded by*</td>
    <td>Vinnova (dnr 2020-02523, dnr 2021-04165); Språkbanken Text
    </td>
    </tr>
    <tr>
    <td>Cite as</td>
    <td>[1]
    </td>
    </tr>
    <tr>
    <td>Related datasets</td>
    <td>Part of the SuperLim 2.0 collection (https://spraakbanken.gu.se/en/resources/superlim)
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Based upon/partially translated from Winogender Schemas [2]
    </td>
    </tr>
    <tr>
    <td></td>
    <td>See SweWinogender v1.0 for a formulation of this task as a pronoun resolution problem.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>II. USAGE</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Key applications</td>
    <td>Diagnose gender bias in natural language inference systems
    </td>
    </tr>
    <tr>
    <td>Intended task(s)/usage(s)</td>
    <td>(1) Indirectly the pronoun interpretation task cast as a natural language inference problem: decide whether a discourse fragment containing a pronoun entails a sentence with the pronoun replaced by a candidate antecedent. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(2) Compare system predictions between pronoun types (masc/fem/gender-neutral)
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(3) Compare system predictions with auxiliary statistics on gender and occupation
    </td>
    </tr>
    <tr>
    <td>Recommended evaluation measures</td>
    <td>(1) Krippendorff's alpha on binary label
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(2) “Gender parity”: The proportion of triples of items differing only by the type of pronoun, which receive identical labels See [3].
    </td>
    </tr>
    <tr>
    <td></td>
    <td>(3) Correlation (Spearman’s rho); plotting/visual inspection. See [2].
    </td>
    </tr>
    <tr>
    <td>Dataset function(s)</td>
    <td>Diagnostics
    </td>
    </tr>
    <tr>
    <td>Recommended split(s)</td>
    <td>Test data only
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>III. DATA</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Primary data*</td>
    <td>Text
    </td>
    </tr>
    <tr>
    <td>Language*</td>
    <td>Swedish
    </td>
    </tr>
    <tr>
    <td>Dataset in numbers*</td>
    <td>624 test items from 104 templates. 312 positive cases ('entailment') and 312 negative cases ('neutral').
    </td>
    </tr>
    <tr>
    <td>Nature of the content*</td>
    <td>The test items are constructed from short discourse templates that contain two participants: one referred to by occupation, and one either by a role description. Furthermore, the templates contain a pronominal reference to one of these participants. The templates are constructed such that the interpretation of the pronoun follows from (common sense) reasoning. Each template gives rise to 6 test items: 3 possibilities depending on whether the feminine (“hon/henne/hennes”), masculine (“han/honom/hans”) or gender-neutral pronoun (“hen/hens”) is used, 2 possibilities depending on whether the hypothesis is entailed or not. A natural language inference model that is not sensitive to gender biases should therefore answer the same way for a triple of test items that only differs in which pronoun they contain.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>The test set is accompanied by an auxiliary dataset that contains two sets of statistics on the association between occupation and gender for the occupations mentioned in the test set. These statistics were extracted from a real-world database and from a corpus, respectively. The auxiliary data can be used to study gender-occupation biases in the system more directly. 
    </td>
    </tr>
    <tr>
    <td>Format*</td>
    <td>Test items: JSON Lines, with 1 test item per line. Test items are given as a pair of sentences ('premise' and 'hypothesis') and a 'label' attribute that says whether the hypothesis is entailed by the premise ('entailment') or not ('neutral'). The metadata ('meta') contains identifying information about the sentence template that generated the test item, and a 'tuple-id' that can be used to calculate parity.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Auxiliary data: TSV file with one occupation per row. Gives the following columns of information: 1) occupation; 2) % female practitioners according to SCB; (3)–(5) % occurences in female-associated contexts using small/medium/large collocate sets.  See [1] for an explanation of the different corpus measures.
    </td>
    </tr>
    <tr>
    <td>Data source(s)*</td>
    <td>The test items are loose translations and/or inspired by the Winogender Schemes of [2].
    </td>
    </tr>
    <tr>
    <td></td>
    <td>The auxiliary data was collected by the first authors of [1], in the context of an MA course. The real-world statistics on gender and occupation were compiled on the basis of Statistics Sweden/SCB’s open data (CC BY 4.0).  Where occupations do not map 1-1 to SCB’s categorization scheme, the supplied statistics are averages over several relevant categories. See [1] for details. The corpus-based statistics on gender-association of occupations where compiled from the Swedish Culturomics Gigaword Corpus  [4].
    </td>
    </tr>
    <tr>
    <td>Data collection method(s)*</td>
    <td>See [1]
    </td>
    </tr>
    <tr>
    <td>Data selection and filtering*</td>
    <td>See [1]
    </td>
    </tr>
    <tr>
    <td>Data preprocessing*</td>
    <td>See [1]
    </td>
    </tr>
    <tr>
    <td>Data labeling*</td>
    <td>Test items contain gold-standard coreference data by design.
    </td>
    </tr>
    <tr>
    <td>Annotator characteristics</td>
    <td>Test item compilation: 1 native speaker of Swedish with PhD in computational linguistics, 1 near-native speaker of Swedish with PhD in (corpus) inguistics. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>IV. ETHICS AND CAVEATS</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Ethical considerations</td>
    <td>The auxiliary data contains information about the distribution between women and men across occupations, and therefore contains data about subpopulations. The data does not contain reference to individuals – neither directly nor indirectly. 
    </td>
    </tr>
    <tr>
    <td>Things to watch out for</td>
    <td>This is meant as a diagnostic, not as a target for training.
    </td>
    </tr>
    <tr>
    <td></td>
    <td>The diagnostic only concerns occupation and gender, and this is only one of the many ways gender bias may be present in a coreference resolution model. In the words of [2]: “[a]s a diagnostic test of gender bias, we view the schemas as having high positive predictive value and low negative predictive value; that is, they may demonstrate the presence of gender bias in a system, but not prove its absence.”
    </td>
    </tr>
    <tr>
    <td></td>
    <td>Although the test items contain a threeway distinction in the pronouns used (han [masc], hon [fem], hen [neutral], the auxiliary data is restricted to a binary gender perspective. For task (3) above, it may however be interesting to compare system predictions for the gender-neutral pronoun (“hen”) items with the auxiliary statistics to better understand how a system handles resolution if this pronoun. 
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>V. ABOUT DOCUMENTATION</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Data last updated*</td>
    <td>20230125 v2.0
    </td>
    </tr>
    <tr>
    <td>Which changes have been made, compared to the previous version*</td>
    <td>Reformulation as a natural language inference task.
    </td>
    </tr>
    <tr>
    <td>Access to previous versions</td>
    <td>Earlier versions available from website.
    </td>
    </tr>
    <tr>
    <td>This document created*</td>
    <td>20210614; Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>This document last updated*</td>
    <td>20230208; Gerlof Bouma (gerlof.bouma@gu.se)
    </td>
    </tr>
    <tr>
    <td>Where to look for further details</td>
    <td>-
    </td>
    </tr>
    <tr>
    <td>Documentation template version*</td>
    <td>v1.1
    </td>
    </tr>
    <tr>
    <td></td>
    <td>
    </td>
    </tr>
    <tr>
    <td>VI. OTHER</td>
    <td>
    </td>
    </tr>
    <tr>
    <td>Related projects</td>
    <td>-
    </td>
    </tr>
    <tr>
    <td>References</td>
    <td>[1] Hansson, Mavromatakis, Adesam, Bouma and Dannélls (2021): The Swedish Winogender Dataset. In Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa), pp452–459. http://www.ep.liu.se/ecp/178/052/ecp2021178052.pdf
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[2] Rudinger, Naradowsky, Leonard and Van Durme (2018): Gender bias in coreference resolution.  In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short  Papers), pp8–14. https://doi.org/10.18653/v1/N18-2002
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[3] Wang, Pruksachatkun, Nangia, Singh, Michael, Hill, Levy and Bowman (2019): SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. In Advances in Neural Information Processing Systems 32. https://papers.nips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf
    </td>
    </tr>
    <tr>
    <td></td>
    <td>[4] Rødven Eide, Tahmasebi  and Borin (2016): The Swedish Culturomics Gigaword corpus: A  one  billion word Swedish reference dataset for NLP. In Digital  Humanities 2016. From Digitization to Knowledge: Resources and Methods for Semantic Processing of Digital Works/Texts, pp8–12. https://ep.liu.se/ecp/126/002/ecp16126002.pdf 
    </td>
    </tr>
    </table>
    
updated: 2023-03-30
doi: 10.23695/wy9w-mw74
